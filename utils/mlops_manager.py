import os
import json
import threading
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass

from utils.conversation_collector import ConversationCollector
from utils.automated_finetuning import AutomatedFinetuner

@dataclass
class MLOpsEvent:
    """MLOps ì´ë²¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤"""
    event_type: str  # "conversation_collected", "training_triggered", "training_completed", "error"
    timestamp: str
    data: Dict[str, Any]
    message: str

class MLOpsManager:
    """í†µí•© MLOps ê´€ë¦¬ ì‹œìŠ¤í…œ (ê°œì„ ëœ ë°°ì¹˜ ì²˜ë¦¬)"""
    
    def __init__(self, finetune_config: Dict[str, Any], conversation_config: Dict[str, Any]):
        self.finetune_config = finetune_config
        self.conversation_config = conversation_config
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.collector = ConversationCollector(conversation_config)
        self.finetuner = AutomatedFinetuner(finetune_config) if finetune_config.get("enabled", True) else None
        
        # ì„¤ì •
        self.batch_size = finetune_config.get("batch_size", 50)
        self.auto_trigger = finetune_config.get("auto_trigger", True)
        self.monitoring_enabled = finetune_config.get("monitoring_enabled", True)
        self.webhook_url = finetune_config.get("webhook_url")
        
        # ğŸš€ ê°œì„ ëœ ìƒíƒœ ê´€ë¦¬
        self.training_in_progress = False
        self.last_training_count = 0  # ë§ˆì§€ë§‰ìœ¼ë¡œ í•™ìŠµí•œ ì‹œì ì˜ ì´ ëŒ€í™” ìˆ˜
        self.current_model_version = None
        self.events_log = []
        self.pending_training_request = False  # ğŸ†• ëŒ€ê¸° ì¤‘ì¸ í•™ìŠµ ìš”ì²­
        
        # ìŠ¤ë ˆë“œ ê´€ë¦¬
        self.training_thread = None
        self.lock = threading.Lock()
        
        # ì´ë²¤íŠ¸ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        self.events_log_path = Path(finetune_config.get("data_path", "./data/finetune")) / "mlops_events.json"
        
        # ê¸°ì¡´ ì´ë²¤íŠ¸ ë¡œê·¸ ë¡œë“œ
        self._load_events_log()
        
        # ì´ˆê¸°í™” ì´ë²¤íŠ¸
        self._log_event("system_initialized", {
            "batch_size": self.batch_size,
            "auto_trigger": self.auto_trigger,
            "finetuner_enabled": self.finetuner is not None
        }, "MLOps ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ¤– MLOps ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {self.batch_size}ê°œ ëŒ€í™”")
        print(f"âš¡ ìë™ íŠ¸ë¦¬ê±°: {'ON' if self.auto_trigger else 'OFF'}")
        print(f"ğŸ”§ íŒŒì¸íŠœë„ˆ: {'í™œì„±í™”' if self.finetuner else 'ë¹„í™œì„±í™”'}")
        print(f"ğŸ“ˆ ëª¨ë‹ˆí„°ë§: {'í™œì„±í™”' if self.monitoring_enabled else 'ë¹„í™œì„±í™”'}")
    
    def _load_events_log(self):
        """ì´ë²¤íŠ¸ ë¡œê·¸ ë¡œë“œ"""
        if self.events_log_path.exists():
            try:
                with open(self.events_log_path, 'r', encoding='utf-8') as f:
                    log_data = json.load(f)
                    self.events_log = [MLOpsEvent(**event) for event in log_data]
                print(f"ğŸ“‚ ì´ë²¤íŠ¸ ë¡œê·¸ ë¡œë“œ: {len(self.events_log)}ê°œ ì´ë²¤íŠ¸")
            except Exception as e:
                print(f"âš ï¸ ì´ë²¤íŠ¸ ë¡œê·¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.events_log = []
    
    def _save_events_log(self):
        """ì´ë²¤íŠ¸ ë¡œê·¸ ì €ì¥"""
        try:
            self.events_log_path.parent.mkdir(parents=True, exist_ok=True)
            
            log_data = []
            for event in self.events_log[-1000:]:  # ìµœê·¼ 1000ê°œë§Œ ì €ì¥
                log_data.append({
                    "event_type": event.event_type,
                    "timestamp": event.timestamp,
                    "data": event.data,
                    "message": event.message
                })
            
            with open(self.events_log_path, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            print(f"âš ï¸ ì´ë²¤íŠ¸ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _log_event(self, event_type: str, data: Dict[str, Any], message: str):
        """ì´ë²¤íŠ¸ ë¡œê¹…"""
        event = MLOpsEvent(
            event_type=event_type,
            timestamp=datetime.now().isoformat(),
            data=data,
            message=message
        )
        
        self.events_log.append(event)
        
        # ì´ë²¤íŠ¸ ì¶œë ¥
        if self.monitoring_enabled:
            print(f"ğŸ“‹ [{event_type}] {message}")
        
        # ë¡œê·¸ ì €ì¥ (ì£¼ê¸°ì ìœ¼ë¡œ)
        if len(self.events_log) % 10 == 0:
            self._save_events_log()
        
        # ì›¹í›… ì•Œë¦¼ (ì¤‘ìš” ì´ë²¤íŠ¸ë§Œ)
        if event_type in ["training_completed", "training_failed", "error"] and self.webhook_url:
            self._send_webhook_notification(event)
    
    def _send_webhook_notification(self, event: MLOpsEvent):
        """ì›¹í›… ì•Œë¦¼ ì „ì†¡ (ë¹„ë™ê¸°)"""
        def send_webhook():
            try:
                import requests
                
                payload = {
                    "text": f"ğŸ¤– MLOps ì•Œë¦¼: {event.message}",
                    "attachments": [{
                        "color": "good" if "completed" in event.event_type else "danger",
                        "fields": [
                            {"title": "ì´ë²¤íŠ¸ íƒ€ì…", "value": event.event_type, "short": True},
                            {"title": "ì‹œê°„", "value": event.timestamp, "short": True},
                            {"title": "ë°ì´í„°", "value": json.dumps(event.data, ensure_ascii=False), "short": False}
                        ]
                    }]
                }
                
                response = requests.post(self.webhook_url, json=payload, timeout=10)
                response.raise_for_status()
                
            except Exception as e:
                print(f"âš ï¸ ì›¹í›… ì „ì†¡ ì‹¤íŒ¨: {e}")
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
        webhook_thread = threading.Thread(target=send_webhook, daemon=True)
        webhook_thread.start()
    
    def _should_trigger_training(self) -> bool:
        """ğŸš€ ê°œì„ ëœ íŠ¸ë¦¬ê±° ì¡°ê±´ íŒë‹¨"""
        current_count = self.collector.stats["total_collected"]
        new_data_count = current_count - self.last_training_count
        
        # ìµœì†Œ ë°°ì¹˜ í¬ê¸°ë§Œí¼ ìƒˆ ë°ì´í„°ê°€ ìŒ“ì˜€ëŠ”ì§€ í™•ì¸
        return new_data_count >= self.batch_size
    
    def _get_new_data_count(self) -> int:
        """ğŸš€ ìƒˆë¡œìš´ ë°ì´í„° ê°œìˆ˜ ë°˜í™˜"""
        current_count = self.collector.stats["total_collected"]
        return current_count - self.last_training_count
    
    def process_conversation(
        self, 
        user_message: str, 
        assistant_response: str,
        user_id: str = "default",
        session_id: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """ğŸš€ ê°œì„ ëœ ëŒ€í™” ì²˜ë¦¬ ë° ìë™ íŒŒì¸íŠœë‹ íŠ¸ë¦¬ê±°"""
        
        # 1. ëŒ€í™” ìˆ˜ì§‘
        collected = self.collector.collect_conversation(
            user_message=user_message,
            assistant_response=assistant_response,
            user_id=user_id,
            session_id=session_id,
            metadata=metadata
        )
        
        current_count = self.collector.stats["total_collected"]
        new_data_count = self._get_new_data_count()
        
        result = {
            "collected": collected,
            "total_collected": current_count,
            "new_data_count": new_data_count,  # ğŸ†• ìƒˆ ë°ì´í„° ê°œìˆ˜
            "should_train": False,
            "pending_count": 0,
            "training_triggered": False,
            "training_queued": False,  # ğŸ†• ëŒ€ê¸°ì—´ ì¶”ê°€ ì—¬ë¶€
            "current_version": self.current_model_version
        }
        
        if collected:
            # ì´ë²¤íŠ¸ ë¡œê¹…
            self._log_event("conversation_collected", {
                "user_id": user_id,
                "session_id": session_id,
                "total_count": current_count,
                "new_data_count": new_data_count,
                "message_length": len(user_message) + len(assistant_response)
            }, f"ìƒˆ ëŒ€í™” ìˆ˜ì§‘ë¨ (ì´ {current_count}ê°œ, ì‹ ê·œ {new_data_count}ê°œ)")
            
            if self.auto_trigger and self.finetuner:
                # ğŸš€ ê°œì„ ëœ íŠ¸ë¦¬ê±° ë¡œì§
                should_train = self._should_trigger_training()
                result["should_train"] = should_train
                result["pending_count"] = max(0, self.batch_size - new_data_count)
                
                if should_train:
                    if not self.training_in_progress:
                        # ì¦‰ì‹œ íŒŒì¸íŠœë‹ ì‹œì‘
                        result["training_triggered"] = self._trigger_async_training()
                    else:
                        # ğŸ†• ì§„í–‰ ì¤‘ì´ë©´ ëŒ€ê¸° ìš”ì²­ ì„¤ì •
                        self.pending_training_request = True
                        result["training_queued"] = True
                        
                        self._log_event("training_queued", {
                            "current_count": current_count,
                            "new_data_count": new_data_count,
                            "batch_size": self.batch_size
                        }, f"íŒŒì¸íŠœë‹ ëŒ€ê¸° ì„¤ì • (ì‹ ê·œ ë°ì´í„° {new_data_count}ê°œ)")
                        
                        print(f"ğŸ“‹ íŒŒì¸íŠœë‹ ëŒ€ê¸° ì„¤ì •: í˜„ì¬ ì§„í–‰ ì¤‘ì´ë¯€ë¡œ ì™„ë£Œ í›„ ì‹¤í–‰ ì˜ˆì • (ì‹ ê·œ {new_data_count}ê°œ)")
        
        return result
    
    def _trigger_async_training(self) -> bool:
        """ğŸš€ ê°œì„ ëœ ë¹„ë™ê¸° íŒŒì¸íŠœë‹ íŠ¸ë¦¬ê±°"""
        try:
            with self.lock:
                if self.training_in_progress:
                    print("âš ï¸ ì´ë¯¸ íŒŒì¸íŠœë‹ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.")
                    return False
                
                self.training_in_progress = True
            
            def training_worker():
                try:
                    current_count = self.collector.stats["total_collected"]
                    new_data_count = current_count - self.last_training_count
                    
                    self._log_event("training_triggered", {
                        "batch_size": self.batch_size,
                        "total_conversations": current_count,
                        "new_data_count": new_data_count,
                        "trigger_type": "automatic"
                    }, f"ìë™ íŒŒì¸íŠœë‹ ì‹œì‘ (ì´ {current_count}ê°œ, ì‹ ê·œ {new_data_count}ê°œ)")
                    
                    print(f"ğŸš€ ìë™ íŒŒì¸íŠœë‹ ì‹œì‘: ì´ {current_count}ê°œ ëŒ€í™” (ì‹ ê·œ {new_data_count}ê°œ)")
                    success_result = self.start_finetuning()
                    
                    if success_result["success"]:
                        # ğŸš€ ì„±ê³µ ì‹œ last_training_count ì—…ë°ì´íŠ¸
                        self.current_model_version = success_result["version"]
                        self.last_training_count = current_count  # í˜„ì¬ ì‹œì ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                        
                        self._log_event("training_completed", {
                            "version": success_result["version"],
                            "training_time": success_result["training_time"],
                            "training_samples": success_result["training_samples"],
                            "output_path": success_result["output_path"],
                            "total_conversations": current_count,
                            "new_data_processed": new_data_count
                        }, f"íŒŒì¸íŠœë‹ ì™„ë£Œ! ë²„ì „: {success_result['version']} (ì‹ ê·œ {new_data_count}ê°œ ì²˜ë¦¬)")
                        
                        print(f"âœ… ìë™ íŒŒì¸íŠœë‹ ì™„ë£Œ! ë²„ì „: {success_result['version']}")
                        
                        # ğŸš€ ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ì´ ìˆìœ¼ë©´ ë‹¤ì‹œ íŠ¸ë¦¬ê±°
                        self._check_pending_training()
                        
                    else:
                        self._log_event("training_failed", {
                            "error": "Unknown error during training",
                            "total_conversations": current_count,
                            "new_data_count": new_data_count
                        }, "íŒŒì¸íŠœë‹ ì‹¤íŒ¨")
                        
                        print("âŒ ìë™ íŒŒì¸íŠœë‹ ì‹¤íŒ¨!")
                        
                except Exception as e:
                    self._log_event("training_failed", {
                        "error": str(e),
                        "error_type": type(e).__name__,
                        "total_conversations": self.collector.stats["total_collected"]
                    }, f"íŒŒì¸íŠœë‹ ì˜¤ë¥˜: {str(e)}")
                    
                    print(f"âŒ ìë™ íŒŒì¸íŠœë‹ ì˜¤ë¥˜: {e}")
                    
                finally:
                    with self.lock:
                        self.training_in_progress = False
            
            # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            self.training_thread = threading.Thread(target=training_worker, daemon=True)
            self.training_thread.start()
            
            return True
            
        except Exception as e:
            with self.lock:
                self.training_in_progress = False
            
            self._log_event("error", {
                "error": str(e),
                "context": "trigger_async_training"
            }, f"íŒŒì¸íŠœë‹ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {str(e)}")
            
            print(f"âŒ íŒŒì¸íŠœë‹ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
            return False
    
    def _check_pending_training(self):
        """ğŸš€ ëŒ€ê¸° ì¤‘ì¸ íŒŒì¸íŠœë‹ ìš”ì²­ í™•ì¸ ë° ì‹¤í–‰"""
        if self.pending_training_request:
            # ëŒ€ê¸° ìš”ì²­ ì¬í™•ì¸
            new_data_count = self._get_new_data_count()
            
            if new_data_count >= self.batch_size:
                self.pending_training_request = False
                
                print(f"ğŸ”„ ëŒ€ê¸° ì¤‘ì´ë˜ íŒŒì¸íŠœë‹ ì‹œì‘: ì‹ ê·œ {new_data_count}ê°œ ë°ì´í„°")
                
                # ì•½ê°„ì˜ ì§€ì—° í›„ ë‹¤ì‹œ íŠ¸ë¦¬ê±° (ì´ì „ ì‘ì—… ì™„ì „ ì™„ë£Œ ë³´ì¥)
                def delayed_trigger():
                    time.sleep(1)  # 1ì´ˆ ëŒ€ê¸°
                    self._trigger_async_training()
                
                delayed_thread = threading.Thread(target=delayed_trigger, daemon=True)
                delayed_thread.start()
                
            else:
                # ì•„ì§ ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ì§€ ì•ŠìŒ
                self.pending_training_request = False
                print(f"ğŸ“‹ ëŒ€ê¸° ìš”ì²­ í•´ì œ: ì‹ ê·œ ë°ì´í„° {new_data_count}ê°œë¡œ ë°°ì¹˜ í¬ê¸° ë¯¸ë‹¬")
    
    def start_finetuning(self, force: bool = False) -> Dict[str, Any]:
        """íŒŒì¸íŠœë‹ ì‹œì‘ (ë™ê¸° ì‹¤í–‰)"""
        if not self.finetuner:
            return {
                "success": False,
                "error": "íŒŒì¸íŠœë„ˆê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                "version": None,
                "training_time": 0,
                "training_samples": 0
            }
        
        try:
            # 1. ë°ì´í„°ì…‹ ìƒì„± (ì „ì²´ ëŒ€í™” ì‚¬ìš©)
            dataset_path = self.collector.export_for_finetuning()
            if not dataset_path:
                return {
                    "success": False,
                    "error": "í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨",
                    "version": None,
                    "training_time": 0,
                    "training_samples": 0
                }
            
            # 2. íŒŒì¸íŠœë‹ ì‹¤í–‰
            result = self.finetuner.run_automated_finetuning(dataset_path)
            
            if result["success"]:
                return {
                    "success": True,
                    "version": result["version"],
                    "output_path": result["output_path"],
                    "training_time": result["training_time"],
                    "training_samples": result["training_samples"]
                }
            else:
                return {
                    "success": False,
                    "error": "íŒŒì¸íŠœë‹ ì‹¤í–‰ ì‹¤íŒ¨",
                    "version": None,
                    "training_time": 0,
                    "training_samples": 0
                }
                
        except Exception as e:
            self._log_event("error", {
                "error": str(e),
                "context": "start_finetuning"
            }, f"íŒŒì¸íŠœë‹ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            
            return {
                "success": False,
                "error": str(e),
                "version": None,
                "training_time": 0,
                "training_samples": 0
            }
    
    def get_status(self) -> Dict[str, Any]:
        """ğŸš€ ê°œì„ ëœ ì „ì²´ MLOps ìƒíƒœ ë°˜í™˜"""
        collector_stats = self.collector.get_stats()
        new_data_count = self._get_new_data_count()
        
        # íŒŒì¸íŠœë‹ ê´€ë ¨ ìƒíƒœ
        training_status = {
            "batch_size": self.batch_size,
            "auto_trigger": self.auto_trigger,
            "in_progress": self.training_in_progress,
            "pending_request": self.pending_training_request,  # ğŸ†•
            "last_training_count": self.last_training_count,
            "new_data_count": new_data_count,  # ğŸ†•
            "pending_count": max(0, self.batch_size - new_data_count),
            "should_train": self._should_trigger_training(),
            "current_version": self.current_model_version,
            "finetuner_enabled": self.finetuner is not None
        }
        
        # ëª¨ë¸ ì •ë³´
        models_info = {
            "base_path": str(self.finetuner.base_output_dir) if self.finetuner else None,
            "backup_count": self.finetuner.backup_count if self.finetuner else 0,
            "available_versions": self.finetuner.get_model_versions() if self.finetuner else []
        }
        
        # ìµœê·¼ ì´ë²¤íŠ¸
        recent_events = []
        for event in self.events_log[-10:]:  # ìµœê·¼ 10ê°œ
            recent_events.append({
                "type": event.event_type,
                "timestamp": event.timestamp,
                "message": event.message,
                "data": event.data
            })
        
        return {
            "collector": collector_stats,
            "training": training_status,
            "models": models_info,
            "events": {
                "total_count": len(self.events_log),
                "recent": recent_events
            },
            "monitoring": {
                "enabled": self.monitoring_enabled,
                "webhook_configured": self.webhook_url is not None
            }
        }
    
    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼...
    def get_training_history(self) -> List[Dict[str, Any]]:
        """íŒŒì¸íŠœë‹ íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        if not self.finetuner:
            return []
        
        return self.finetuner.get_training_history()
    
    def get_events_log(self, event_type: Optional[str] = None, limit: int = 100) -> List[Dict[str, Any]]:
        """ì´ë²¤íŠ¸ ë¡œê·¸ ì¡°íšŒ"""
        events = self.events_log
        
        # íƒ€ì… í•„í„°ë§
        if event_type:
            events = [e for e in events if e.event_type == event_type]
        
        # ìµœì‹  ìˆœìœ¼ë¡œ ì œí•œ
        events = events[-limit:]
        
        return [{
            "type": event.event_type,
            "timestamp": event.timestamp,
            "message": event.message,
            "data": event.data
        } for event in events]
    
    def update_settings(self, **kwargs) -> Dict[str, Any]:
        """ì„¤ì • ë™ì  ì—…ë°ì´íŠ¸"""
        updated = {}
        
        if "batch_size" in kwargs and kwargs["batch_size"] > 0:
            old_batch = self.batch_size
            self.batch_size = kwargs["batch_size"]
            updated["batch_size"] = {"old": old_batch, "new": self.batch_size}
        
        if "auto_trigger" in kwargs:
            old_trigger = self.auto_trigger
            self.auto_trigger = kwargs["auto_trigger"]
            updated["auto_trigger"] = {"old": old_trigger, "new": self.auto_trigger}
        
        if "collection_enabled" in kwargs:
            old_enabled = self.collector.enabled
            self.collector.enabled = kwargs["collection_enabled"]
            updated["collection_enabled"] = {"old": old_enabled, "new": self.collector.enabled}
        
        if "monitoring_enabled" in kwargs:
            old_monitoring = self.monitoring_enabled
            self.monitoring_enabled = kwargs["monitoring_enabled"]
            updated["monitoring_enabled"] = {"old": old_monitoring, "new": self.monitoring_enabled}
        
        # ì„¤ì • ë³€ê²½ ì´ë²¤íŠ¸ ë¡œê¹…
        if updated:
            self._log_event("settings_updated", updated, f"ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤: {list(updated.keys())}")
        
        return updated
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        # ëŒ€í™” ìˆ˜ì§‘ ì„±ëŠ¥
        collector_stats = self.collector.get_stats()
        
        # íŒŒì¸íŠœë‹ ì„±ëŠ¥
        training_history = self.get_training_history() if self.finetuner else []
        
        avg_training_time = 0
        total_trainings = len([h for h in training_history if h.get("success", False)])
        
        if total_trainings > 0:
            successful_trainings = [h for h in training_history if h.get("success", False)]
            avg_training_time = sum(h.get("training_time_seconds", 0) for h in successful_trainings) / len(successful_trainings)
        
        # ì´ë²¤íŠ¸ í†µê³„
        event_stats = {}
        for event in self.events_log:
            event_type = event.event_type
            event_stats[event_type] = event_stats.get(event_type, 0) + 1
        
        return {
            "collection": {
                "total_collected": collector_stats["total_collected"],
                "filtered_out": collector_stats["filtered_out"],
                "collection_rate": collector_stats["total_collected"] / (collector_stats["total_collected"] + collector_stats["filtered_out"]) * 100 if (collector_stats["total_collected"] + collector_stats["filtered_out"]) > 0 else 0,
                "file_size_kb": collector_stats["file_size_kb"]
            },
            "training": {
                "total_trainings": total_trainings,
                "failed_trainings": len(training_history) - total_trainings,
                "avg_training_time_seconds": avg_training_time,
                "success_rate": total_trainings / len(training_history) * 100 if training_history else 0
            },
            "events": event_stats,
            "system": {
                "uptime_hours": (datetime.now() - datetime.fromisoformat(self.events_log[0].timestamp)).total_seconds() / 3600 if self.events_log else 0,
                "training_in_progress": self.training_in_progress
            }
        }
    
    def cleanup_old_data(self, keep_days: int = 30) -> Dict[str, Any]:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        try:
            from datetime import timedelta
            cutoff_date = datetime.now() - timedelta(days=keep_days)
            
            # ì˜¤ë˜ëœ ì´ë²¤íŠ¸ ë¡œê·¸ ì •ë¦¬
            original_count = len(self.events_log)
            self.events_log = [
                event for event in self.events_log 
                if datetime.fromisoformat(event.timestamp) > cutoff_date
            ]
            removed_events = original_count - len(self.events_log)
            
            # ë¡œê·¸ ì €ì¥
            self._save_events_log()
            
            # ì •ë¦¬ ì´ë²¤íŠ¸ ë¡œê¹…
            self._log_event("cleanup_completed", {
                "keep_days": keep_days,
                "removed_events": removed_events
            }, f"ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {removed_events}ê°œ ì´ë²¤íŠ¸ ì œê±°")
            
            return {
                "success": True,
                "removed_events": removed_events,
                "remaining_events": len(self.events_log),
                "cutoff_date": cutoff_date.isoformat()
            }
            
        except Exception as e:
            self._log_event("error", {
                "error": str(e),
                "context": "cleanup_old_data"
            }, f"ë°ì´í„° ì •ë¦¬ ì˜¤ë¥˜: {str(e)}")
            
            return {
                "success": False,
                "error": str(e)
            }
    
    def shutdown(self):
        """MLOps ë§¤ë‹ˆì € ì¢…ë£Œ"""
        try:
            # ì§„í–‰ ì¤‘ì¸ í›ˆë ¨ ëŒ€ê¸°
            if self.training_in_progress and self.training_thread:
                print("ğŸ”„ ì§„í–‰ ì¤‘ì¸ íŒŒì¸íŠœë‹ ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
                self.training_thread.join(timeout=300)  # 5ë¶„ ëŒ€ê¸°
            
            # ìµœì¢… ì´ë²¤íŠ¸ ë¡œê·¸ ì €ì¥
            self._save_events_log()
            
            self._log_event("system_shutdown", {}, "MLOps ì‹œìŠ¤í…œì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            print("ğŸ›‘ MLOps ë§¤ë‹ˆì € ì¢…ë£Œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ MLOps ë§¤ë‹ˆì € ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")